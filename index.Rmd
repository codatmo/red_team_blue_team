---
title: "Model reproduction checklist"
author: "Breck Baldwin"
date: "3/8/2021"
output: 
  html_document:
    includes:
       in_header: _html/ga.html
---

# Model overview

This document exists in the repository at [https://github.com/codatmo/model_template](https://github.com/codatmo/model_template) as `index.Rmd` and rendered in html as `index.html`. The releases can be downloaded at [https://github.com/codatmo/model_template/releases](https://github.com/codatmo/model_template/releases) which includes this file. 

The goal of this example model is to provide a template for reproducing COVID models in the CoDatMo framework. The model presented is a three parameter regression with artificial data. 

This model is part of the CoDatMo (Co)vid (Dat)a (Mo)deling site (https://codatmo.github.io/) which is intended to replicate and make available important COVID models written in Bayesian modeling languages like Stan or PyMC3.

### Validation checklist items 

* Model released on github: https://github.com/codatmo/model_template
* Problem description
* Model description: Research goals, references, supplementary description as necessary.
* Data
  + Data generating process
  + Data munging and examination
* Stan program
* Running model
  + Small data set to validate model execution (not done)
  + Run on availble data
  + Examine model output
* Model validation
  + Report posterior diagnostics
  + Prior predictive check parameters/predictions
  + Parameter recovery with simulated data
  + Posterior predictive check
  + Cross validation (not done)
  + Simulation based calibration (SBC) (not done)

## Problem description

This toy example attempts to model the relationship between phone calls to government services (111 calls) that report COVID-19 symptoms and hospital admissions that test positive for COVID-19 14 days later. 

## Model description
The model runs a simple linear regression with three parameters being estimated:

$$
y_n \sim \operatorname{normal}(\alpha + \beta X_n, \, \sigma) \\
\alpha \sim \operatorname{normal}(0,1000) \\
\beta \sim \operatorname{half\_normal}(0,2) \\
\sigma \sim \operatorname{normal}(500,300)
$$

The data is not centered or scaled for this example which leads to some oddly parameterized priors. This is not recommended practice but it helps keep the example simple.

## Data 

The data are artificially generated with generating values drawn randomly from priors and resides in `data/data.R`. The generating script is at `generate_data.R`. The random seed should be removed or changed if the code is rerun with the expectation of getting different data. Usually we don't have access to generating parameters so we won't consider them here. Later we will generate data as part of model validation.

## Data generating process

The data generating process is as follows: Person calls 111 reporting COVID symptoms as determined by the call center. We expect a baseline admission rate for COVID at hospitals and some percentage of the people who called will eventually be admitted to the hospital 14 days later. 
```{r fig.height=1}
library(dagitty)
graph <- dagitty("dag {x_calls_111 -> y_cvd_hosp}")
coordinates(graph) <- list(x=c(x_calls_111=1, y_cvd_hosp=2),
                           y=c(x_calls_111=0, y_cvd_hosp=0))
plot(graph)
```

The above causal graph treats 111 calls as causal for hospital admissions which is certainly incorrect. A more complete causal model would be sensitive to the underlying COVID rate but we are keeping the model simple. 

Below the data are loaded.

```{r comment=NA}
source(file="data/data.R")
# vars are: 'n_days_data','x_calls_111', 'y_cvd_hosp'
data <- data.frame(x_calls_111, y_cvd_hosp)

head(data)
```

### Data munging and examination
There is no data cleaning or processing. We will graph it however.

```{r}
library(ggplot2)
ggplot(data) + aes(x=x_calls_111,y=y_cvd_hosp) + geom_point()
```

The conversion to Stan input given the above data is as follows:

```{r echo=TRUE, message=FALSE, comment=NA}
stan_data <- list(N=nrow(data), x_calls_111=data$x_calls_111, y_cvd_hosp=data$y_cvd_hosp,
                  compute_likelihood=1, compute_prediction=0)
```

Note that the variables `compute_likelihood=` and `compute_prediction=` control Stan program execution with `1` meaning the relevant code is run and `0` meaning it will not be run. 

## Stan program

The Stan model is located at `model_template/stan/linear_regression.stan`:

```{r echo=FALSE, message=FALSE, comment=NA}
stan_file <- "stan/linear_regression.stan"
lines <- readLines(stan_file)
cat(paste(lines, "\n", sep=""), sep="")

get_data_block <- function(lines) {
  data_lines <- c()
  accumulate_line <- FALSE
  for (line in lines) {
    if (str_detect(line,"^data\\s*\\{")) {
      accumulate_line <- TRUE
    }
    if (str_detect(line,"^parameters\\s*\\{")) {
      accumulate_line <- FALSE
      break
    }
    if (accumulate_line) {
      data_lines <- c(data_lines,line)
    }
  }
  return(data_lines)
}
```

## Running model

```{r echo=TRUE, message=FALSE, comment=NA}
library(cmdstanr)
model <- cmdstan_model(file.path("stan","linear_regression.stan"))
stan_data <- list(N=nrow(data), x_calls_111=data$x_calls_111, y_cvd_hosp=data$y_cvd_hosp,
                  compute_likelihood=1, compute_prediction=0)
fit <- model$sample(data=stan_data, seed=999, chains=4)
```

Viewing a text based summary of the fit:

```{r comment=NA}
fit$cmdstan_summary()
```

Viewing the posteriors graphically yeilds via the very useful `bayesplot` package:

```{r echo=TRUE, message=FALSE, warning=FALSE}
library(bayesplot)
mcmc_hist(fit$draws(variables=c("sigma_sd", "beta_coef_111_call", "alpha_intercept")))
```


## Model validation

Below are the diagnostics used to help validate the model. 

### Run posterior diagnostics

There are standard diagnostics that look for errors in the posterior.

```{r comment=NA}
fit$cmdstan_diagnose()
```

* Treedepth warnings passed
* Divergence check passed
* E-BFMI satisfactory
* R-hat values satisfactory

### Prior predictive check

The prior predictive check estimates the model parameters without the likelihood being used. The resulting draws are then used to predict new data via predictive application of the likelihood given the draws. Note that `compute_likelihood = 0` prevents the likelihood being computed in the model. 

```{r echo=TRUE, message=FALSE, warning=FALSE, comment=NA}
library(cmdstanr)
library(rstan)
library(ggplot2)
library(bayesplot)
library(tidyr)

model <- cmdstan_model(file.path("stan", "linear_regression.stan"))
stan_data <- list(N=100, x_calls_111=data$x_calls_111, y_cvd_hosp=y_cvd_hosp,
                  compute_likelihood=0, compute_prediction=1)

fit <- model$sample(data=stan_data, seed=999, chains=4)

mcmc_hist(fit$draws(variables=c("sigma_sd", "beta_coef_111_call", "alpha_intercept")))
```

Above we see the posterior of the priors without seeing any data. Generally some justification for prior distributions is expected. The above are weakly informative in that they cover a broad range of plausible values. 

#### Plotting simulations from priors

Draws from the above posteriors allow for generation of simulated output data given input data `x_calls_111`. Note that `compute_likelihood=0` prevents adding information from the data. 

```{r}
rs_fit <- rstan::read_stan_csv(fit$output_files())
rs_ex <- rstan::extract(rs_fit)
random_draws <- sample(1:nrow(rs_ex$y_cvd_hosp_pred), 10, replace=FALSE)
draws <- data.frame(t(rs_ex$y_cvd_hosp_pred[random_draws,]))
names(draws) <- random_draws
draw_names <- colnames(draws)

p_data2 <- cbind(data,draws)

p_long_data <- gather(p_data2,draw,y_sim,draw_names)

p <- ggplot(data=p_long_data, aes(x=x_calls_111)) +
            geom_point(aes(y=y_sim, group=draw, color=draw), size=.5) +
            geom_line(aes(y=y_cvd_hosp), color="black", size=.5)
print(p)

```

Actual data is plotted as a black line for context. At this point some comforting statements are made that the prior's informativeness is minimal and that Bayes himself would bless the entire effort were he alive to do so. 

### Parameter recovery with simulated data

Parameter recovery establishes that for some small set of values the model reasons properly. We pick a draw from the above distributions, simulate data with it and then attempt to recover the parameters that we simulated with. We can look at the above graph and pick expected outliers or close to actual data. For this we pick 2959 as a middle-of-the-road example. 

```{r echo=TRUE, message=FALSE, warning=FALSE, comment=NA}
#Pick one arbitrary draw from the prior distribution
draw <- 2959
stan_data <- list(N=100, 
                  x_calls_111=data$x_calls_111,
                  y_cvd_hosp=rs_ex$y_cvd_hosp_pred[draw,],
                  compute_likelihood=1, compute_prediction=0)
fit <- model$sample(data=stan_data, seed=999, chains=4)

fit$cmdstan_summary()
report <- paste(sprintf("\nDraw number %d", draw),
sprintf("actual alpha_intercept=%.2f", rs_ex$alpha_intercept[draw]),
sprintf("actual beta_coef_111_call=%.2f", rs_ex$beta_coef_111_call[draw]),
sprintf("actual sigma_sd=%.2f", rs_ex$sigma_sd[draw]), sep="\n")
cat(report)

```

The mean estimates for `alpha_intercept` and `sigma_sd` fit within the 5% to to 95% interval.The `beta_coef_111_call` is just outside the interval. 

### Posterior predictive check

Like the prior predictive check but we include actual data in estimating the parameters. Note that both `compute_liklihood=1`,  `compute_prediction=1` and that the actual data is supplied in place of simlated data from above.

 
```{r comment=NA}
stan_data <- list(N=nrow(data), x_calls_111=data$x_calls_111, y_cvd_hosp=y_cvd_hosp,
                  compute_likelihood=1, compute_prediction=1)

fit <- model$sample(data=stan_data, seed=999, chains=4)
rs_fit <- rstan::read_stan_csv(fit$output_files())
rs_ex <- rstan::extract(rs_fit)
random_draws <- sample(1:nrow(rs_ex$y_cvd_hosp_pred), 10, replace=FALSE)
draws <- data.frame(t(rs_ex$y_cvd_hosp_pred[random_draws,]))
names(draws) <- random_draws
draw_names <- colnames(draws)

p_data2 <- cbind(data,draws)

p_long_data <- gather(p_data2,draw,y_sim,draw_names)

p <- ggplot(data=p_long_data, aes(x=x_calls_111)) +
            geom_point(aes(y=y_sim, group=draw, color=draw), size=.5) +
            geom_line(aes(y=y_cvd_hosp), color="black", size=.5)
print(p)
```

Actual data as a black line, 10 draws from the posterior shown. Clearly data helps.  

### Cross validation

### SBC validation


